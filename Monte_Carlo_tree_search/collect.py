#collect self playing data
import os
import random
from collections import deque
import copy
import pickle
import time
import chess_rule_for_mcts as chess_rule
from mcts import MCTSPlayer
from config import CONFIG
from net import PolicyValueNet
from self_play import MCT_start_self_play

#define the whole process of playing deta collecting
class CollectPipeline:
    def __init__(self, init_model=None):
        self.gp = chess_rule.GamePosition()
        #playing params
        self.temp = 1  #tempreture
        self.n_playout = CONFIG['play_out']  #stimulate times per move
        self.c_puct = CONFIG['c_puct']  #weight of u
        self.buffer_size = CONFIG['buffer_size'] 
        self.data_buffer = deque(maxlen=self.buffer_size)
        self.iters = 0
   
    #load the model
    def load_model(self):
        model_path = CONFIG['pytorch_model_path']
        try:
            self.policy_value_net = PolicyValueNet(model_file=model_path)
            print('Loaded the newest model')
        except:
            self.policy_value_net = PolicyValueNet()
            print('Loaded the initial model')
        self.mcts_player = MCTSPlayer(self.policy_value_net.policy_value_fn,
                                      c_puct=self.c_puct,
                                      n_playout=self.n_playout,
                                      is_selfplay=1)
        
    def collect_selfplay_data(self, n_games=1):
        #collect data generated by self playing
        for i in range(n_games):
            self.load_model()  #load the newest model
            winner_is_white, play_data = MCT_start_self_play(self.mcts_player, temp=self.temp, is_shown=False)
            play_data = list(play_data)[:]
            self.episode_len = len(play_data)
            if os.path.exists(CONFIG['train_data_buffer_path']):
                while True:
                    try:
                        with open(CONFIG['train_data_buffer_path'], 'rb') as data_dict:
                            data_file = pickle.load(data_dict)
                            self.data_buffer = deque(maxlen=self.buffer_size)
                            self.data_buffer.extend(data_file['data_buffer'])
                            self.iters = data_file['iters']
                            del data_file
                            self.iters += 1
                            self.data_buffer.extend(play_data)
                        print('Successfully loaded data.')
                        break
                    except:
                        time.sleep(30)
            else:
                self.data_buffer.extend(play_data)
                self.iters += 1
            data_dict = {'data_buffer': self.data_buffer, 'iters': self.iters}
            with open(CONFIG['train_data_buffer_path'], 'wb') as data_file:
                pickle.dump(data_dict, data_file)
        return self.iters
    
    def run(self):
        #start collecting data
        try:
            while True:
                iters = self.collect_selfplay_data()
                print('batch i: {}, episode_len: {}'.format(
                    iters, self.episode_len))
        except KeyboardInterrupt:
            print('\n\rquit')

collecting_pipeline = CollectPipeline(init_model='current_policy.pkl')
collecting_pipeline.run()
